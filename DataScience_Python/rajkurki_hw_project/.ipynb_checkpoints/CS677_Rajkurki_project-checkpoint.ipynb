{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to CS677 Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset : https://archive.ics.uci.edu/ml/datasets/bank+marketing \n",
    "\n",
    "<b> The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y). </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input variables:\n",
    "### bank client data:\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                   \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "\n",
    "3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "\n",
    "5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "\n",
    "6 - balance: average yearly balance, in euros (numeric) \n",
    "\n",
    "7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "### related with the last contact of the current campaign:\n",
    "\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "\n",
    "10 - day: last contact day of the month (numeric)\n",
    "\n",
    "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "\n",
    "12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "\n",
    "### other attributes:\n",
    "\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "\n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "Output variable (desired target):\n",
    "17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset collected in marketing campaigns done by the bank. The dataset has both numerical and categorical columns. Goal is to build a model which will help the marketing team to identify potential consumers who will be more likely to invest in new financial products ex: term deposit offered by bank. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Outcome Tasks:\n",
    "1.\tDoing the extract discovery analysis work.\n",
    "2.\tFeatures datatypes and distribution of data analysis.\n",
    "3.\tFeatures selection.\n",
    "4.\tData Cleanup and preparation.\n",
    "5.\tUse of Pandas profiling module.\n",
    "6.\tData visualization using matplotlib.pyplot and seaborn packages.\n",
    "7.\tBuilding the prediction models.\n",
    "8.\tEvaluating the Accuracy, precision, recall for each class across models.\n",
    "9.\tSelecting the best model with highest accuracy, precision and recall.\n",
    "10.\tSaving the model into pickle file and exposing the best model functionality through flask/streamlet Apis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:blue\">  <b> EXPLORATORY DATA ANALYSIS WORK </b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bank_df = pd.read_csv(r'bank-full.csv',sep=';',header=0)\n",
    "bank_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages which we required for Exploratory data analysis (EDA)\n",
    "import pandas as pd  # to store tabular data\n",
    "import numpy as np  # to do some math\n",
    "import matplotlib.pyplot as plt  # a popular data visualization tool\n",
    "import seaborn as sns  # another popular data visualization tool\n",
    "%matplotlib inline  \n",
    "plt.style.use('fivethirtyeight')  # a popular data visualization theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Subscribing to the term deposit (outcome)  has been dictated by couple of prominent features, lets see how they impact for outcome </b>\n",
    " 1. housing loan\n",
    " 2. personal loan\n",
    " 3. previous campaign outcome\n",
    " 4. balance.\n",
    " 5. education\n",
    " 6. marital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bank_df.columns)\n",
    "df_job=bank_df['job'].value_counts().to_frame().reset_index()\n",
    "joborder=list(df_job.iloc[:,0])\n",
    "printjobnames=joborder\n",
    "joborder.sort(reverse=False)\n",
    "joborder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bank_df.columns[0:len(bank_df.columns)-1]:\n",
    "    \n",
    "    if col==\"job\":\n",
    "        print(printjobnames)\n",
    "        bank_df[col+'new']=bank_df[col].map(lambda x: joborder.index(x)+1)\n",
    "        plt.hist(bank_df[bank_df['y']=='no'][col+'new'], 30, color='g',alpha=0.5, label='Not Subscribed to TD')\n",
    "        plt.hist(bank_df[bank_df['y']=='yes'][col+'new'], 30, color='y',alpha=0.5, label='Subscribed to TD')\n",
    "        bank_df.drop(columns=['jobnew'],inplace=True)\n",
    "       \n",
    "    else:\n",
    "        plt.hist(bank_df[bank_df['y']=='no'][col], 30, color='g',alpha=0.5, label='Not Subscribed to TD')\n",
    "        plt.hist(bank_df[bank_df['y']=='yes'][col], 30, color='y',alpha=0.5, label='Subscribed to TD')\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of {}'.format(col))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the impact of data values from the features with respect to deposits. Following can be inferred.\n",
    "\n",
    "1. Young age group are more interested in term deposits. The amount of customers subscribing to term deposit gradually reduces after a certain thershold age of 40 . \n",
    "\n",
    "2. Management, Technician, admin , bluecollar jobs have significant term deposits compared to other professionals. \n",
    "3. Divorced people are unlikely to subscribe into term deposits.\n",
    "4. Default people will not be subscribed into term deposits.\n",
    "5. People with no housing/personal loan are more subscribed into term deposits.\n",
    "6. Good way in direct marketing campaign to convince the customers is through cellular connection instead of unknown & telephone.\n",
    "7. December month will have zero customers enrolling into term deposit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df=bank_df.groupby('y').agg({'y':'count'})\n",
    "sum_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> About 8% of users have been subscribed into term deposits</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_df=bank_df.groupby(['marital','y']).agg({'balance':'sum','y':'count'})\n",
    "marital_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate Analysis: \n",
    "1. Duration and y ( response outcome)\n",
    "2. Education,balance and y .\n",
    "3. Marital, balance and y . \n",
    "4. Job and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['duration_status'] = np.select([(bank_df['duration']< bank_df['duration'].mean())], [\"Below Average\"],default=\"Above Average\")\n",
    "duration_deposit=pd.crosstab(bank_df['duration_status'], bank_df['y']).apply(lambda r: round(r/r.sum(), 2) * 100, axis=1)\n",
    "\n",
    "duration_deposit.plot(kind='bar',stacked=False,cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.drop(columns=['duration_status'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bank_df[\"education\"].value_counts().index:\n",
    "    for j in bank_df[\"y\"].value_counts().index:\n",
    "        education_balance_amt = bank_df[(bank_df[\"education\"] == i) & (bank_df[\"y\"] == j)][\"balance\"].sum()\n",
    "        percentage = round(education_balance_amt*100 / bank_df[\"balance\"].sum(),3)\n",
    "        print(f\"Education level '{i}' and Deposit status '{j}' amount: {education_balance_amt}, percentage: {percentage}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> Persons with higher secondary , tertiary degrees have high balances </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bank_df[\"marital\"].value_counts().index:\n",
    "    for j in bank_df[\"y\"].value_counts().index:\n",
    "        marital_balance_amt = bank_df[(bank_df[\"marital\"] == i) & (bank_df[\"y\"] == j)][\"balance\"].sum()\n",
    "        percentage = round(marital_balance_amt*100 / bank_df[\"balance\"].sum(),3)\n",
    "        print(f\"Marital level '{i}' and Deposit status '{j}' amount: {marital_balance_amt}, percentage: {percentage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Insights on Marital feature : \n",
    "    Individuals who are single , will have higher rate of subscribing into term deposits.\n",
    "    Among the balances of all category of individuals who subscribed into term deposits , the divorced category records show a less balance.\n",
    "  \n",
    "</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(bank_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the categorical variables : job, marital , education, default, housing, loan, contact, poutcome, month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=['job','marital','education','default','housing','loan','contact','poutcome','month','duration']\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(9,16))\n",
    "    sns.countplot(bank_df[col],hue=\"y\",data=bank_df)\n",
    "    #sns.barplot(bank_df[col].value_counts(),bank_df[col].value_counts().index,hue=\"y\",data=bank_df)\n",
    "    plt.title(col)\n",
    "    plt.tight_layout(pad=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(bank_df,hue=\"y\",palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Profiling\n",
    "\n",
    "1. About 1.8% of people have been defaulted.\n",
    "2. More than 50% of users are having housing loan.\n",
    "3. Most of them are having secondary education.\n",
    "4. About 16% of users do have personal loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "#profile = ProfileReport(bank_df)\n",
    "#profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bank_df=bank_df.copy()\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "le = LabelEncoder()\n",
    "model_bank_df['y']=le.fit_transform(model_bank_df['y'])\n",
    "\n",
    "model_bank_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bank_df.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(model_bank_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['y'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:blue\">  <b> FEATURE CONSTRUCTION </b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Data cleanup : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poutcome and Contact columns have : unknown values , which is not a good set of rows, so we will be taking out those rows.\n",
    "from poutcome => unknown, contact => unknown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_index=bank_df[(bank_df['poutcome']=='unknown') | (bank_df['contact']=='unknown')].index\n",
    "#37029 records.\n",
    "\n",
    "bank_df.drop(lst_index,inplace=True)\n",
    "bank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class CustomEncoder(TransformerMixin):\n",
    "    def __init__(self, col, ordering=None):\n",
    "        self.ordering = ordering\n",
    "        self.col = col\n",
    "        \n",
    "    def transform(self, df):\n",
    "        X = df.copy()\n",
    "        X[self.col] = X[self.col].map(lambda x: self.ordering.index(x))\n",
    "        return X\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class CustomDummifier(TransformerMixin):\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X, columns=self.cols)\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_forencoder=dict()\n",
    "dict_forencoder['default']=['no', 'yes']\n",
    "dict_forencoder['housing']=['no', 'yes']\n",
    "dict_forencoder['loan']=['no', 'yes']\n",
    "dict_forencoder['y']=['no','yes']\n",
    "dict_forencoder['contact']=['telephone','cellular']\n",
    "\n",
    "#cd=CustomDummifier(cols=['poutcome'])\n",
    "#bank_featured=cd.fit_transform(bank_df)\n",
    "\n",
    "bank_featured=bank_df\n",
    "cd=CustomDummifier(cols=['poutcome','month','job','marital','education'])\n",
    "bank_featured=cd.fit_transform(bank_featured)\n",
    "\n",
    "\n",
    "for colname in ['default','housing','loan','y','contact']:\n",
    "    ce=CustomEncoder(col=colname,ordering=dict_forencoder[colname])\n",
    "    bank_featured=ce.fit_transform(bank_featured)\n",
    "\n",
    "\n",
    "\n",
    "bank_featured.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_featured.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_featured.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_featured.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_featured.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_featured.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:blue\">  <b> FEATURE SELECTION </b></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our feature matrix\n",
    "#bank_featured.drop(columns=['job','marital','education'],inplace=True)\n",
    "\n",
    "X = bank_featured.drop('y', axis=1)\n",
    "\n",
    "# create our response variable\n",
    "y = bank_featured['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "\n",
    "class CustomCorrelationChooser(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, response, cols_to_keep=[], threshold=None):\n",
    "        # store the response series\n",
    "        self.response = response\n",
    "        # store the threshold that we wish to keep\n",
    "        self.threshold = threshold\n",
    "        # initialize a variable that will eventually\n",
    "        # hold the names of the features that we wish to keep\n",
    "        self.cols_to_keep = cols_to_keep\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # the transform method simply selects the appropiate\n",
    "        # columns from the original dataset\n",
    "        return X[self.cols_to_keep]\n",
    "        \n",
    "    def fit(self, X, *_):\n",
    "        # create a new dataframe that holds both features and response\n",
    "        df = pd.concat([X, self.response], axis=1)\n",
    "        # store names of columns that meet correlation threshold\n",
    "        self.cols_to_keep = df.columns[df.corr()[df.columns[-1]].abs() > self.threshold]\n",
    "        # only keep columns in X, for example, will remove response variable\n",
    "        self.cols_to_keep = [c for c in self.cols_to_keep if c in X.columns]\n",
    "        return self\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def get_best_model_and_accuracy(model, params, X, y):\n",
    "    grid = GridSearchCV(model,           # the model to grid search\n",
    "                        params,          # the parameter set to try \n",
    "                        error_score=0., \n",
    "                        n_jobs=-1)  # if a parameter set raises an error, continue and set the performance as a big, fat 0\n",
    "    grid.fit(X, y)           # fit the model and parameters\n",
    "    # our classical metric for performance\n",
    "    print(\"Best Accuracy: {}\".format(grid.best_score_))\n",
    "    # the best parameters that caused the best accuracy\n",
    "    print(\"Best Parameters: {}\".format(grid.best_params_))\n",
    "    # the average time it took a model to fit to the data (in seconds)\n",
    "    print(\"Average Time to Fit (s): {}\".format(round(grid.cv_results_['mean_fit_time'].mean(), 3)))\n",
    "    # the average time it took a model to predict out of sample data (in seconds)\n",
    "    # this metric gives us insight into how this model will perform in real-time analysis\n",
    "    print(\"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "# Import four machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set up some parameters for our grid search\n",
    "# We will start with four different machine learning models\n",
    "# logistic regression, KNN, Decision Tree, and Random Forest\n",
    "lr_params = {'C':[1e-1, 1e0, 1e1, 1e2], 'penalty':['l1', 'l2']}\n",
    "knn_params = {'n_neighbors': [1, 3, 5, 7]}\n",
    "tree_params = {'max_depth': [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n",
    "forest_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 1, 3, 5, 7]}\n",
    "\n",
    "\n",
    "# instantiate the four machine learning models\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "knn = KNeighborsClassifier()\n",
    "d_tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "ccc = CustomCorrelationChooser(response=y)\n",
    "ccc_pipe = Pipeline([('correlation_select', ccc), \n",
    "                     ('classifier', d_tree)])\n",
    "tree_pipe_params = {'classifier__max_depth': \n",
    "                    [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n",
    "# make a copy of the decisino tree pipeline parameters\n",
    "ccc_pipe_params = deepcopy(tree_pipe_params)\n",
    "\n",
    "# update that dictionary with feature selector specific parameters\n",
    "ccc_pipe_params.update({\n",
    "               'correlation_select__threshold':[0.1, 0.2,.3, 0.4]})\n",
    "\n",
    "print(ccc_pipe_params)\n",
    "\n",
    "# better than original (by a little, and a bit faster on \n",
    "# average overall\n",
    "get_best_model_and_accuracy(ccc_pipe, ccc_pipe_params, X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc_selected=CustomCorrelationChooser(y,threshold=0.2)\n",
    "ccc_selected.fit_transform(X)\n",
    "ccc_selected.cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "k_best = SelectKBest(f_classif, k=4)\n",
    "k_best.fit_transform(X, y)\n",
    "p_values = pd.DataFrame({'column': X.columns, 'p_value': k_best.pvalues_}).sort_values('p_value')\n",
    "\n",
    "p_values.head(10)\n",
    "p_values[p_values['p_value'] < .05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values[p_values['p_value'] >= .05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = SelectKBest(f_classif)\n",
    "\n",
    "# Make a new pipeline with SelectKBest\n",
    "select_k_pipe = Pipeline([('k_best', k_best), \n",
    "                          ('classifier', d_tree)])\n",
    "\n",
    "select_k_best_pipe_params = deepcopy(tree_pipe_params)\n",
    "\n",
    "select_k_best_pipe_params.update({'k_best__k':list(range(3,15))+['all'],  # the 'all' literally does nothing to subset\n",
    "                                 })\n",
    "print(select_k_best_pipe_params)\n",
    "# comparable to our results with correlationchooser\n",
    "get_best_model_and_accuracy(select_k_pipe, select_k_best_pipe_params, X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_best = SelectKBest(f_classif,k=3)\n",
    "k_best.fit_transform(X,y)\n",
    "p_values = pd.DataFrame({'column': X.columns, 'p_value': k_best.pvalues_}).sort_values('p_value')\n",
    "p_values.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,[3,7,11,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a class that choses features based\n",
    "# on feature importances according to the fitting phase\n",
    "# of a separate decision tree classifier\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "select_from_pipe = Pipeline([('select', SelectFromModel(DecisionTreeClassifier())), \n",
    "                             ('classifier', d_tree)])\n",
    "tree_pipe_params = {'classifier__max_depth': [1, 3, 5, 7]}\n",
    "select_from_pipe_params = deepcopy(tree_pipe_params)\n",
    "\n",
    "select_from_pipe_params.update({\n",
    "              'select__threshold': [.01, .05, .1, \"mean\", \"median\", \"2.*mean\"],\n",
    "              'select__estimator__max_depth': [None, 1, 3, 5, 7]\n",
    "              })\n",
    "\n",
    "print(select_from_pipe_params)\n",
    "\n",
    "# not better than original\n",
    "get_best_model_and_accuracy(select_from_pipe, \n",
    "                            select_from_pipe_params, \n",
    "                            X, y)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from_pipe.set_params(**{'select__threshold': 0.01, \n",
    "                               'select__estimator__max_depth': None, \n",
    "                               'classifier__max_depth': 1})\n",
    "\n",
    "\n",
    "# fit our pipeline to our data\n",
    "select_from_pipe.steps[0][1].fit(X, y)\n",
    "\n",
    "# list the columns that the SVC selected by calling the get_support() method from SelectFromModel\n",
    "X.columns[select_from_pipe.steps[0][1].get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> 1. sanity check </mark>\n",
    "\n",
    "<mark> 2. If we only the worst columns </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "# If we only the worst columns\n",
    "the_worst_of_X = X[X.columns.drop(['housing', 'duration', 'poutcome_failure', 'poutcome_success'])]\n",
    "the_best_of_X = X.loc[:,['age','balance','housing','day','duration','campaign','pdays','previous','poutcome_success','job_technician']]\n",
    "the_super_best_of_X = X.loc[:,['housing', 'duration', 'poutcome_failure', 'poutcome_success']]\n",
    "\n",
    "# much worst than the original 0.8203 without removing anything\n",
    "# goes to show, that selecting the wrong features will \n",
    "# hurt us in predictive performance\n",
    "get_best_model_and_accuracy(d_tree, tree_params, the_worst_of_X, y)  \n",
    "get_best_model_and_accuracy(d_tree, tree_params, the_best_of_X, y)\n",
    "get_best_model_and_accuracy(d_tree, tree_params, the_super_best_of_X, y)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=X.columns[select_from_pipe.steps[0][1].get_support()].to_frame().reset_index()['index']\n",
    "X_bestfeatures=X.loc[:,np.array(features)]\n",
    "X_bestfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:blue\">  <b>MODEL BUILDING </b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Knn algorithm , finding the best K and then finding the accuracy using that K value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:,['housing', 'duration', 'poutcome_failure', 'poutcome_success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=1, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "accuracy = []\n",
    "\n",
    "for i in [3,5,7,9,11,13,15]:\n",
    "  classifier = KNeighborsClassifier(n_neighbors=i,p=2,metric='euclidean') # start with k=3, using L^2 norm\n",
    "  classifier.fit(X_train_sc,y_train)\n",
    "  y_pred =  classifier.predict(X_test_sc)\n",
    "  accuracy.append(accuracy_score(y_test,y_pred))\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lst_x=range(3,17,2)\n",
    "plt.plot(lst_x,accuracy,\"r-\")\n",
    "ax = plt.axes()\n",
    "ax.set_xticks([3,5,7,9,11,13,15])\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy of Predictions\")\n",
    "plt.title(\"Plot of Accuracy vs k value for kNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best value of k is 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=[]\n",
    "TP=[]\n",
    "FP=[]\n",
    "TN=[]\n",
    "FN=[]\n",
    "accuracy_table=[]\n",
    "TPR_lst=[]\n",
    "TNR_lst=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier_bestK = KNeighborsClassifier(n_neighbors=9) # start with k=3, using L^2 norm, dont't need last two args since those are defaults\n",
    "\n",
    "classifier_bestK.fit(X_train_sc,y_train)\n",
    "y_pred=classifier_bestK.predict(X_test_sc)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "cm=confusion_matrix(y_test,y_pred,labels=[0,1])\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = cm,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "true_neg=cm[0][0]\n",
    "true_pos=cm[1][1]\n",
    "false_pos=cm[0][1]\n",
    "false_neg=cm[1][0]\n",
    "\n",
    "TPR = true_pos/(true_pos + false_neg)\n",
    "TNR = true_neg/(true_neg + false_pos)\n",
    "\n",
    "Model.append('Knn')\n",
    "TN.append(true_neg)\n",
    "TP.append(true_pos)\n",
    "FP.append(false_pos)\n",
    "FN.append(false_neg)\n",
    "TPR_lst.append(TPR)\n",
    "TNR_lst.append(TNR)\n",
    "accuracy_table.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=13)\n",
    "accuracy_dtree=[]\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "  tree_clf = DecisionTreeClassifier(max_depth=i)\n",
    "  tree_clf.fit(X_train,y_train)\n",
    "  y_pred =  tree_clf.predict(X_test)\n",
    "  accuracy_dtree.append(accuracy_score(y_test,y_pred))\n",
    "\n",
    "accuracy_dtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lst_x=range(1,16,1)\n",
    "plt.plot(lst_x,accuracy_dtree,\"r-\")\n",
    "ax = plt.axes()\n",
    "ax.set_xticks([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "plt.xlabel(\"Maxdepth\")\n",
    "plt.ylabel(\"Accuracy of Predictions\")\n",
    "plt.title(\"Plot of Maxdepth vs Accuracy value for Decision tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max depth of 4 will have greater accuracy compared to other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5)\n",
    "tree_clf.fit(X_train,y_train)\n",
    "y_pred =  tree_clf.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "cm=confusion_matrix(y_test,y_pred,labels=[0,1])\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = cm,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "true_neg=cm[0][0]\n",
    "true_pos=cm[1][1]\n",
    "false_pos=cm[0][1]\n",
    "false_neg=cm[1][0]\n",
    "\n",
    "TPR = true_pos/(true_pos + false_neg)\n",
    "TNR = true_neg/(true_neg + false_pos)\n",
    "\n",
    "Model.append('DecisionTree')\n",
    "TN.append(true_neg)\n",
    "TP.append(true_pos)\n",
    "FP.append(false_pos)\n",
    "FN.append(false_neg)\n",
    "TPR_lst.append(TPR)\n",
    "TNR_lst.append(TNR)\n",
    "accuracy_table.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def max_frequency_label(ensemble_values):\n",
    "    \"\"\"\n",
    "                  function which returns the maximum value of passed in object.\n",
    "                   Parameters:\n",
    "                   ensemble_values (String): String containing the value.\n",
    "\n",
    "                   Returns:\n",
    "                   String: Returns a maximum occurance character from the string.\n",
    "\n",
    "        \"\"\"\n",
    "    res = Counter(ensemble_values)\n",
    "    res = max(res, key=res.get)\n",
    "    return str(res)\n",
    "\n",
    "from collections import Counter\n",
    "def min_frequency_label(ensemble_values):\n",
    "    \"\"\"\n",
    "                  function which returns the maximum value of passed in object.\n",
    "                   Parameters:\n",
    "                   ensemble_values (String): String containing the value.\n",
    "\n",
    "                   Returns:\n",
    "                   String: Returns a maximum occurance character from the string.\n",
    "\n",
    "        \"\"\"\n",
    "    res = Counter(ensemble_values)\n",
    "    res = min(res, key=res.get)\n",
    "    return str(res)\n",
    "\n",
    "\n",
    "\n",
    "dict_best={}\n",
    "dict_best_matrix={}\n",
    "for N in range(1,11):\n",
    "    drange=[1,2,3,4,5]\n",
    "\n",
    "\n",
    "    print(' during the number of decision trees in Random forest : {} '.format(N))\n",
    "    for d in range(1,6):\n",
    "\n",
    "        rf_clf = RandomForestClassifier(n_estimators=N,criterion='entropy',max_depth=d)\n",
    "        rf_clf.fit(X_train,y_train)\n",
    "        y_pred = rf_clf.predict(X_test)\n",
    "        mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        acc_calc=metrics.accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy for tree : {} and depth : {} is {}:\".format(N,d,acc_calc))\n",
    "        \n",
    "        keyval=str(N)+'_'+str(d)+'_tree'\n",
    "        dict_best[keyval]=acc_calc\n",
    "        dict_best_matrix[keyval]=mat\n",
    "\n",
    "bestkey=max_frequency_label(dict_best)\n",
    "print(' THE BEST KEY COMBINATION OF N is {} and d is : {} '.format(bestkey.split('_')[0],bestkey.split('_')[1]))\n",
    "print(' THE BEST ACCURACY FOR BEST COMBINATION OF N and d is : {}'.format(dict_best[bestkey]))\n",
    "true_neg=dict_best_matrix[bestkey][0][0]\n",
    "true_pos=dict_best_matrix[bestkey][1][1]\n",
    "false_pos=dict_best_matrix[bestkey][0][1]\n",
    "false_neg=dict_best_matrix[bestkey][1][0]\n",
    "\n",
    "TPR = true_pos/(true_pos + false_neg)\n",
    "TNR = true_neg/(true_neg + false_pos)\n",
    "Model.append('RandomForestClassifier')\n",
    "TN.append(true_neg)\n",
    "TP.append(true_pos)\n",
    "FP.append(false_pos)\n",
    "FN.append(false_neg)\n",
    "TPR_lst.append(TPR)\n",
    "TNR_lst.append(TNR)\n",
    "accuracy_table.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' BEST CONFUSUION MATRIX IS : {}'.format(dict_best_matrix[bestkey]))\n",
    "sns.heatmap(dict_best_matrix[bestkey],square=True, annot=True, fmt = 'd', cbar=True, xticklabels=['Not subscribed','Subscribed'], yticklabels=['Not subscribed','Subscribed'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian NB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = mat,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy for gaussian model is ', accuracy)\n",
    "Model.append('GaussianNB')\n",
    "tn, fp, fn, tp = mat.ravel()\n",
    "TN.append(tn)\n",
    "TP.append(tp)\n",
    "FP.append(fp)\n",
    "FN.append(fn)\n",
    "TPR_lst.append(tp/(tp + fn))\n",
    "TNR_lst.append(tn/(tn + fp))\n",
    "accuracy_table.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "log_reg.fit(X_train,y_train)\n",
    "y_pred=log_reg.predict(X_test)\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = mat,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy for Logistic Regression model is ', accuracy)\n",
    "Model.append('LogisticRegression')\n",
    "tn, fp, fn, tp = mat.ravel()\n",
    "TN.append(tn)\n",
    "TP.append(tp)\n",
    "FP.append(fp)\n",
    "FN.append(fn)\n",
    "TPR_lst.append(tp/(tp + fn))\n",
    "TNR_lst.append(tn/(tn + fp))\n",
    "accuracy_table.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC # support vector classification\n",
    "c=10\n",
    "# Fit model to data\n",
    "linear_svm = LinearSVC(C=c,loss=\"hinge\")\n",
    "linear_svm.fit(X_train_sc, y_train)\n",
    "y_pred = linear_svm.predict(X_test_sc)\n",
    "\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = mat,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy for SVM  model is ', accuracy)\n",
    "tn, fp, fn, tp = mat.ravel()\n",
    "Model.append('LinearSVC')\n",
    "TN.append(tn)\n",
    "TP.append(tp)\n",
    "FP.append(fp)\n",
    "FN.append(fn)\n",
    "TPR_lst.append(tp/(tp + fn))\n",
    "TNR_lst.append(tn/(tn + fp))\n",
    "accuracy_table.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING CLASSIFIER  AND BAGGING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_clf = LogisticRegression(solver='liblinear')\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "        estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "        voting = 'hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred=voting_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = mat,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy obtained is ',accuracy)\n",
    "Model.append('VotingClassifier')\n",
    "tn, fp, fn, tp = mat.ravel()\n",
    "TN.append(tn)\n",
    "TP.append(tp)\n",
    "FP.append(fp)\n",
    "FN.append(fn)\n",
    "TPR_lst.append(tp/(tp + fn))\n",
    "TNR_lst.append(tn/(tn + fp))\n",
    "accuracy_table.append(accuracy)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "        DecisionTreeClassifier(), n_estimators=500,\n",
    "        max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "cm_display=metrics.ConfusionMatrixDisplay(confusion_matrix = mat,display_labels=['Not subscribed','Subscribed'])\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy obtained is ',accuracy)\n",
    "\n",
    "Model.append('BaggingClassifier')\n",
    "tn, fp, fn, tp = mat.ravel()\n",
    "TN.append(tn)\n",
    "TP.append(tp)\n",
    "FP.append(fp)\n",
    "FN.append(fn)\n",
    "TPR_lst.append(tp/(tp + fn))\n",
    "TNR_lst.append(tn/(tn + fp))\n",
    "accuracy_table.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Model':Model,'TP':TP,'FP':FP,'TN':TN,'FN':FN,'accuracy':accuracy_table,'TPR':TPR_lst,'TNR':TNR_lst})\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model outputs :\n",
    "\n",
    "Among all the models , Decision tree classifier performs better with higher accuracy and good TPR and TNR numbers as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tree_clf, open('model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
